{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"ML_Task_Baidu02.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"I2nd9XGEYILh","colab_type":"code","outputId":"3f32558b-2e69-4657-8688-6e27ee6ed8b0","executionInfo":{"status":"ok","timestamp":1585619344618,"user_tz":-480,"elapsed":54670,"user":{"displayName":"Kane Huang","photoUrl":"","userId":"02321211776127070843"}},"colab":{"base_uri":"https://localhost:8080/","height":229}},"source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":0,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","Selecting previously unselected package google-drive-ocamlfuse.\n","(Reading database ... 144542 files and directories currently installed.)\n","Preparing to unpack .../google-drive-ocamlfuse_0.7.18-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n","Unpacking google-drive-ocamlfuse (0.7.18-0ubuntu1~ubuntu18.04.1) ...\n","Setting up google-drive-ocamlfuse (0.7.18-0ubuntu1~ubuntu18.04.1) ...\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","··········\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n","Please enter the verification code: Access token retrieved correctly.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EMilQmpWYfSU","colab_type":"code","colab":{}},"source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cWIbVuc3YfYS","colab_type":"code","colab":{}},"source":["from drive.ML_Study import * # 让driver连接云盘的ML_Study"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VRKoCfS2Yfdq","colab_type":"code","outputId":"7b1a6d70-09e0-4a8c-ac75-c5428c235b90","executionInfo":{"status":"error","timestamp":1585619032256,"user_tz":-480,"elapsed":14172,"user":{"displayName":"Kane Huang","photoUrl":"","userId":"02321211776127070843"}},"colab":{"base_uri":"https://localhost:8080/","height":133}},"source":["# For console \n","function ClickConnect(){\n","  console.log(\"Working\"); \n","  document\n","    .querySelector(\"#top-toolbar > colab-connect-button\")\n","    .shadowRoot\n","    .querySelector(\"#connect\")\n","    .click()\n","}\n"," \n","setInterval(ClickConnect,60000)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-a25e4085266e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    function ClickConnect(){\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"v9Plafj7Yi2U","colab_type":"code","outputId":"194755ee-1ea0-483e-a0b6-ee0069c13092","executionInfo":{"status":"ok","timestamp":1585619365504,"user_tz":-480,"elapsed":8404,"user":{"displayName":"Kane Huang","photoUrl":"","userId":"02321211776127070843"}},"colab":{"base_uri":"https://localhost:8080/","height":700}},"source":["pip install transformers"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/ba/dda44bbf35b071441635708a3dd568a5ca6bf29f77389f7c7c6818ae9498/transformers-2.7.0-py3-none-any.whl (544kB)\n","\u001b[K     |████████████████████████████████| 552kB 2.7MB/s \n","\u001b[?25hCollecting tokenizers==0.5.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n","\u001b[K     |████████████████████████████████| 3.7MB 14.9MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 36.0MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n","\u001b[K     |████████████████████████████████| 870kB 31.3MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.27)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n","Requirement already satisfied: botocore<1.16.0,>=1.15.27 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.27)\n","Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->transformers) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.27->boto3->transformers) (2.8.1)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=eb6b43f1252156531ee07d68cb44e797bc47d266ae5d2722d8dd370f8613651d\n","  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.7.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Yvp-0Zu-YdMY","colab_type":"code","colab":{}},"source":["import json\n","import numpy as np\n","from tqdm import tqdm\n","import os\n","import tensorflow as tf\n","from transformers import *"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SVdnF7qhYILk","colab_type":"code","outputId":"04a68f60-e6a1-4236-e9b8-934d76b23c55","executionInfo":{"status":"ok","timestamp":1585619373347,"user_tz":-480,"elapsed":2283,"user":{"displayName":"Kane Huang","photoUrl":"","userId":"02321211776127070843"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["print('Lodaing BERT')\n","# 最好使用自己下载的文件，否则可能会因为连不上下载文件的服务器而报错\n","pretrainedModel_path = 'drive/ML_Study/bert-base-chinese'\n","tokenizer = BertTokenizer.from_pretrained(os.path.join(pretrainedModel_path, 'vocab.txt'))\n","config = BertConfig.from_json_file(os.path.join(pretrainedModel_path, 'config.json'))\n","print('==========END==========')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Lodaing BERT\n"],"name":"stdout"},{"output_type":"stream","text":["Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n"],"name":"stderr"},{"output_type":"stream","text":["==========END==========\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BxBQ-WVnYILn","colab_type":"code","colab":{}},"source":["# 生成新的SPO\n","# def load_data(path):\n","#     D = []\n","#     with open(path, encoding='utf-8') as f:\n","#         for l in f.readlines():\n","#             l = json.loads(l)\n","#             D.append({\n","#                 'text': l['text'],\n","#                 'spo_list': [\n","#                     (spo['subject'], spo['predicate'], spo['object']['@value'])\n","#                     for spo in l['spo_list']\n","#                 ]\n","#             })\n","#     return D\n","\n","def load_data(filename):\n","    D = []\n","    with open(filename, encoding='utf-8') as f:\n","        for l in f:\n","            l = json.loads(l)\n","            D.append({\n","                'text': l['text'],\n","                'spo_list': [(spo['subject'], spo['predicate'], spo['object'])\n","                             for spo in l['spo_list']]\n","            })\n","    return D\n","\n","# 得到对应值的初始下标\n","def search(pattern, sequence):\n","    n = len(pattern)\n","    for i in range(len(sequence)):\n","        if sequence[i:i + n] == pattern:\n","            return i\n","    return -1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k87GbBEBYILs","colab_type":"code","outputId":"0a21232f-e3a4-4399-fe96-164968b92b3e","executionInfo":{"status":"ok","timestamp":1585619385882,"user_tz":-480,"elapsed":10169,"user":{"displayName":"Kane Huang","photoUrl":"","userId":"02321211776127070843"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["print('Loading Data')\n","train_data = load_data('drive/ML_Study/B4K_Data/train_data.json')\n","# train_data = load_data('drive/ML_Study/Baidu_ERE_Data/sample_data.json')\n","valid_data = load_data('drive/ML_Study/B4K_Data/dev_data.json')\n","# test_data = load_data('./data/example.test')\n","print('=========END==========')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loading Data\n","=========END==========\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fJCc335EYILu","colab_type":"code","colab":{}},"source":["# category mapping\n","# def get_mapping(mapping_path):\n","#     predicate2id, id2predicate = {}, {}\n","#     with open(mapping_path, encoding='utf-8') as f:\n","#         for l in f.readlines():\n","#             l = json.loads(l)\n","#             if l['predicate'] not in predicate2id:\n","#                 id2predicate[len(predicate2id)] = l['predicate']\n","#                 predicate2id[l['predicate']] = len(predicate2id)\n","#     return predicate2id, id2predicate\n","    \n","# mapping_path = 'drive/ML_Study/Baidu_ERE_Data/schema.json'\n","# predicate2id, id2predicate = get_mapping(mapping_path)\n","predicate2id, id2predicate = {}, {}\n","\n","with open('drive/ML_Study/B4K_Data/all_50_schemas') as f:\n","    for l in f:\n","        l = json.loads(l)\n","        if l['predicate'] not in predicate2id:\n","            id2predicate[len(predicate2id)] = l['predicate']\n","            predicate2id[l['predicate']] = len(predicate2id)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iL0eEjztYIL3","colab_type":"code","colab":{}},"source":["def get_input(data,tokenizer,predicate2id,maxlen=128):\n","        token_ids_t1, segment_ids_t1, position_ids_t1= [], [], [] # X for S\n","        token_ids_t2, segment_ids_t2, position_ids_t2= [], [], [] # X for PO\n","        subject_labels, object_labels = [], []# Y\n","        for d in data:\n","            # 针对一个text\n","            token_id, segment_id, position_id = tokenizer.encode_plus(d['text'], max_length=maxlen,pad_to_max_length=True).values()\n","\n","            SPOes = {}            \n","            for s, p, o in d['spo_list']:\n","                sw = s\n","                s = tokenizer.encode(s)[1:-1]# 101 是 CLS 102 是ESP 这里只是为了得到s内部值的ID\n","                p = predicate2id[p] # 对category进行映射得到对应的ID\n","                o = tokenizer.encode(o)[1:-1] \n","                s_idx = search(s, token_id) # 对text进行映射\n","                o_idx = search(o, token_id)\n","                if s_idx != -1 and o_idx != -1:\n","                    s = (s_idx, s_idx + len(s) - 1) # s 为 subject 的位置（始终态）\n","                    o = (o_idx, o_idx + len(o) - 1, p) # 包含了 object 和 predicate\n","                    if s not in SPOes:\n","                        SPOes[s] = []\n","                        # forT2，在text_a的基础上加上text_a(subject)\n","                        token_idv2, segment_idv2, position_idv2 = tokenizer.encode_plus(text=d['text'], text_pair=sw*4, max_length=maxlen,pad_to_max_length=True).values()\n","                        token_ids_t2.append(token_idv2)\n","                        segment_ids_t2.append(segment_idv2)\n","                        position_ids_t2.append(position_idv2)\n","                    SPOes[s].append(o) # 可一对多\n","                    \n","            if SPOes:\n","                # Model 1\n","                # subject label\n","                subject_label = np.zeros((len(token_id), 2)) #两层\n","                Ss = SPOes.keys()\n","                for s in Ss:\n","                    subject_label[s[0], 0] = 1 # label第一层保存初始位置\n","                    subject_label[s[1], 1] = 1 # 第二层保存末态位置\n","                token_ids_t1.append(token_id)\n","                segment_ids_t1.append(segment_id)\n","                position_ids_t1.append(position_id)\n","                subject_labels.append(subject_label) \n","                \n","                # Model 2\n","                # object和predicate label\n","                for s in Ss:\n","                    object_label = np.zeros((len(token_id), len(predicate2id), 2)) \n","                    for o in SPOes.get(s, []): # 得到对应的po 若sub_id不存在，则返回空[]\n","                        object_label[o[0], o[2], 0] = 1 # o[2] 是predicate\n","                        object_label[o[1], o[2], 1] = 1 \n","                    object_labels.append(object_label)\n","                    # 其余与 subject 预测数据的 label处理类似,只不过这里label也同时标上了\n","        print('Converting to tensor.....')\n","        return (\n","            tf.convert_to_tensor(tf.constant(token_ids_t1)),\n","            tf.convert_to_tensor(tf.constant(segment_ids_t1)),\n","            tf.convert_to_tensor(tf.constant(position_ids_t1)),\n","            tf.convert_to_tensor(tf.constant(token_ids_t2)), \n","            tf.convert_to_tensor(tf.constant(segment_ids_t2)), \n","            tf.convert_to_tensor(tf.constant(position_ids_t2)),\n","            tf.convert_to_tensor(tf.constant(subject_labels)), \n","            tf.convert_to_tensor(tf.constant(object_labels))\n","        )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"raEmjSUXYIL5","colab_type":"code","outputId":"23a92da7-5026-4d97-fedc-a885e9b6c907","executionInfo":{"status":"ok","timestamp":1585574868379,"user_tz":-480,"elapsed":114754,"user":{"displayName":"Kane Huang","photoUrl":"","userId":"02321211776127070843"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["print('Contructing Input')\n","token_ids_t1, segment_ids_t1, position_ids_t1,token_ids_t2, segment_ids_t2, position_ids_t2, subject_labels, object_labels = get_input(train_data,tokenizer,predicate2id)\n","print('=========END==========')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Contructing Input\n","Converting to tensor.....\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kSFMnmOlRDKE","colab_type":"code","colab":{}},"source":["token_ids_t1_valid, segment_ids_t1_valid, position_ids_t1_valid,token_ids_t2_valid, segment_ids_t2_valid, position_ids_t2_valid, subject_labels_valid, object_labels_valid = get_input(valid_data,tokenizer,predicate2id)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pzk78h-BYIL7","colab_type":"code","colab":{}},"source":["print(len(token_ids_t1) == len(train_data))\n","print(len(token_ids_t1) == len(subject_labels))\n","print(len(token_ids_t2) == len(object_labels))\n","# 数据集中有空的spolist"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jra4s9ohYIL9","colab_type":"code","colab":{}},"source":["def extract_SPOes(text):\n","    \"\"\"\n","    抽取输入text所包含的三元组\n","    \"\"\"\n","    tokens = tokenizer.tokenize(text, max_length=maxlen)\n","    token_ids, segment_ids = tokenizer.encode(text, max_length=maxlen)\n","    # 抽取subject\n","    subject_preds = subject_model.predict([[token_ids], [segment_ids]])\n","    start = np.where(subject_preds[0, :, 0] > 0.6)[0]  # 输出坐标\n","    end = np.where(subject_preds[0, :, 1] > 0.5)[0]\n","    subjects = []\n","    for i in start:\n","        j = end[end >= i]\n","        if len(j) > 0:\n","            j = j[0]\n","            subjects.append((i, j))\n","    if subjects:\n","        SPOes = []\n","        # 根据s内存在的subject个数进行复制\n","        token_ids = np.repeat([token_ids], len(subjects), 0) # axis = 0 增加行\n","        segment_ids = np.repeat([segment_ids], len(subjects), 0)\n","        subjects = np.array(subjects)\n","        # 传入subject，抽取object和predicate\n","        object_preds = object_model.predict([token_ids, segment_ids, subjects]) \n","        for subject, object_pred in zip(subjects, object_preds):\n","            start = np.where(object_pred[:, :, 0] > 0.6) # 二维坐标\n","            end = np.where(object_pred[:, :, 1] > 0.5)\n","            for _start, predicate1 in zip(*start): \n","                for _end, predicate2 in zip(*end):\n","                    if _start <= _end and predicate1 == predicate2:\n","                        SPOes.append((subject, predicate1, (_start, _end)))\n","                        break\n","        return [\n","            (\n","                tokenizer.decode(token_ids[0, s[0]:s[1] + 1], tokens[s[0]:s[1] + 1]),\n","                id2predicate[p],\n","                tokenizer.decode(token_ids[0, o[0]:o[1] + 1], tokens[o[0]:o[1] + 1])\n","            ) for s, p, o in spoes\n","        ]\n","    else:\n","        return []"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"znBaCAh6YIMA","colab_type":"code","colab":{}},"source":["class SPO(tuple):\n","    def __init__(self, spo):\n","        self.spox = (\n","            tuple(tokenizer.tokenize(spo[0])),\n","            spo[1],\n","            tuple(tokenizer.tokenize(spo[2])),\n","        )\n","\n","    def __hash__(self):\n","        return self.spox.__hash__()\n","\n","    def __eq__(self, spo):\n","        return self.spox == spo.spox"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9d3xvRIfYIMC","colab_type":"code","colab":{}},"source":["def evaluate(data):\n","    X, Y, Z = 1e-10, 1e-10, 1e-10\n","    f = open('dev_pred.json', 'w', encoding='utf-8')\n","    pbar = tqdm()\n","    for d in data:\n","        R = set([SPO(spo) for spo in extract_SPOes(d['text'])]) # spo 是 tup！\n","        T = set([SPO(spo) for spo in d['spo_list']])\n","        X += len(R & T)\n","        Y += len(R)\n","        Z += len(T)\n","        f1, precision, recall = 2 * X / (Y + Z), X / Y, X / Z\n","        pbar.update()\n","        pbar.set_description('f1: %.5f, precision: %.5f, recall: %.5f' %\n","                             (f1, precision, recall))\n","        s = json.dumps(\n","            {\n","                'text': d['text'],\n","                'spo_list': list(T),\n","                'spo_list_pred': list(R),\n","                'new': list(R - T),\n","                'lack': list(T - R),\n","            },\n","            ensure_ascii=False,\n","            indent=4)\n","        f.write(s + '\\n')\n","    pbar.close()\n","    f.close()\n","    return f1, precision, recall"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rtHrL8qOYIMD","colab_type":"code","colab":{}},"source":["class Evaluator(tf.keras.callbacks.Callback):\n","    \"\"\"\n","    评估和保存模型\n","    \"\"\"\n","    def __init__(self):\n","        self.best_val_f1 = 0.\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        optimizer.apply_ema_weights()\n","        f1, precision, recall = evaluate(valid_data)\n","        if f1 >= self.best_val_f1:\n","            self.best_val_f1 = f1\n","#             train_model.save_weights('./save/best_model.weights')\n","        optimizer.reset_old_weights()\n","        print('f1: %.5f, precision: %.5f, recall: %.5f, best f1: %.5f\\n' %\n","              (f1, precision, recall, self.best_val_f1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qdxzq_usYIMF","colab_type":"code","colab":{}},"source":["class Subject_Model(TFBertPreTrainedModel):\n","    # def dummy_inputs(self):\n","    #     \"\"\" Dummy inputs to build the network.\n","\n","    #     Returns:\n","    #         tf.Tensor with dummy inputs\n","    #     \"\"\"\n","    #     return {\"input_ids\": tf.constant(DUMMY_INPUTS)}\n","    \n","    def __init__(self, config, *inputs, **kwargs):\n","        super().__init__(config, *inputs, **kwargs)\n","        self.bert = TFBertMainLayer(config, name=\"bert\")\n","        # self.dense01 = tf.keras.layers.Dense(units = 1024, activation=tf.nn.relu)\n","        self.dense02 = tf.keras.layers.Dense(units = 128*2, activation=tf.nn.softmax)\n","\n","    def call(self, inputs, **kwargs):\n","        _, x = self.bert(inputs, **kwargs)\n","        # x = self.dense01(x)\n","        x = self.dense02(x)\n","        x = tf.keras.layers.Lambda(lambda x: x**2)(x)\n","        output = tf.reshape(x, (-1,128,2))\n","        return output\n","\n","class Object_Model(TFBertPreTrainedModel):\n","    # def dummy_inputs(self):\n","    #     \"\"\" Dummy inputs to build the network.\n","\n","    #     Returns:\n","    #         tf.Tensor with dummy inputs\n","    #     \"\"\"\n","    #     return {\"input_ids\": tf.constant(DUMMY_INPUTS)}\n","    \n","    def __init__(self, config, *inputs, **kwargs):\n","        super().__init__(config, *inputs, **kwargs)\n","        self.bert = TFBertMainLayer(config, name=\"bert\")\n","        # self.dense01 = tf.keras.layers.Dense(units = , activation=tf.nn.relu)\n","        self.dense02 = tf.keras.layers.Dense(units = 128*48*2, activation=tf.nn.sigmoid)\n","\n","    def call(self, inputs, **kwargs):\n","        _, x = self.bert(inputs, **kwargs)\n","        # x = self.dense01(x)\n","        x = self.dense02(x)\n","        output = tf.reshape(x, (-1,128,48,2))\n","        return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XggfXDxc5pA3","colab_type":"code","colab":{}},"source":["# train_dataset  = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n","# train_dataset = train_dataset.shuffle(buffer_size=3000)    \n","# train_dataset = train_dataset.batch(32)\n","# train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n","\n","# valid_dataset = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))\n","# valid_dataset = train_dataset.shuffle(buffer_size=3000)    \n","# valid_dataset = train_dataset.batch(32)\n","# valid_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sifNSZAqmakv","colab_type":"code","colab":{}},"source":["token_ids_t1[:7000].shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JX7exFWemO4a","colab_type":"code","colab":{}},"source":["def myloss(y_true, y_pred):\n","\treturn tf.reduce_sum(tf.keras.losses.binary_crossentropy(y_true,y_pred),axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4VtCUWbYYIMK","colab_type":"code","colab":{}},"source":["config = BertConfig.from_json_file(os.path.join(pretrainedModel_path, 'config.json'))\n","subject_model = Subject_Model.from_pretrained(pretrainedModel_path,config=config)\n","\n","subject_model.compile(\n","           optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), \n","           loss=myloss, \n","           metrics=[tf.keras.metrics.BinaryAccuracy()]) # accuracy没有好的 所以随便选了一个"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CDkZlCdYgISl","colab_type":"code","outputId":"be2ff99a-90d0-459e-ffdf-f63c7a91832e","executionInfo":{"status":"ok","timestamp":1585574975319,"user_tz":-480,"elapsed":564,"user":{"displayName":"Kane Huang","photoUrl":"","userId":"02321211776127070843"}},"colab":{"base_uri":"https://localhost:8080/","height":226}},"source":["subject_model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"subject__model_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bert (TFBertMainLayer)       multiple                  102267648 \n","_________________________________________________________________\n","dense_1 (Dense)              multiple                  196864    \n","=================================================================\n","Total params: 102,464,512\n","Trainable params: 102,464,512\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sMwyHlUUYIML","colab_type":"code","outputId":"53f66db9-6a75-4793-f3af-25f94d1cac69","executionInfo":{"status":"ok","timestamp":1585577028247,"user_tz":-480,"elapsed":2051109,"user":{"displayName":"Kane Huang","photoUrl":"","userId":"02321211776127070843"}},"colab":{"base_uri":"https://localhost:8080/","height":264}},"source":["# subject_model.fit(x={'input_ids':token_ids_t1[:7000], 'attention_mask':position_ids_t1[:7000], 'token_type_ids':segment_ids_t1[:7000]},\n","#           y=subject_labels[:7000],\n","#           epochs=6,\n","#           validation_steps=7,\n","#           validation_data=([token_ids_t1[7000:],position_ids_t1[7000:],segment_ids_t1[7000:]], subject_labels[7000:]),\n","#           batch_size=16\n","#            )\n","subject_model.fit(x={'input_ids':token_ids_t1, 'attention_mask':position_ids_t1, 'token_type_ids':segment_ids_t1},\n","          y=subject_labels,\n","          epochs=6,\n","          validation_steps=7,\n","          validation_data=([token_ids_t1_valid, position_ids_t1_valid, segment_ids_t1_valid], subject_labels_valid),\n","          batch_size=16\n","           )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/6\n","438/438 [==============================] - 339s 775ms/step - loss: 11.8944 - binary_accuracy: 0.9840 - val_loss: 6.2265 - val_binary_accuracy: 0.9901\n","Epoch 2/6\n","438/438 [==============================] - 337s 769ms/step - loss: 6.0983 - binary_accuracy: 0.9903 - val_loss: 5.5866 - val_binary_accuracy: 0.9910\n","Epoch 3/6\n","438/438 [==============================] - 338s 771ms/step - loss: 5.6787 - binary_accuracy: 0.9909 - val_loss: 5.2607 - val_binary_accuracy: 0.9915\n","Epoch 4/6\n","438/438 [==============================] - 337s 769ms/step - loss: 5.3926 - binary_accuracy: 0.9911 - val_loss: 5.0390 - val_binary_accuracy: 0.9915\n","Epoch 5/6\n","438/438 [==============================] - 336s 767ms/step - loss: 5.1109 - binary_accuracy: 0.9913 - val_loss: 4.7980 - val_binary_accuracy: 0.9916\n","Epoch 6/6\n","438/438 [==============================] - 338s 771ms/step - loss: 4.8190 - binary_accuracy: 0.9914 - val_loss: 4.6360 - val_binary_accuracy: 0.9919\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f7c904c73c8>"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"code","metadata":{"id":"IsHONLstGBmh","colab_type":"code","outputId":"56daf3d3-b30d-45ee-cc35-4f1514c2dbb0","executionInfo":{"status":"ok","timestamp":1585566634168,"user_tz":-480,"elapsed":92575,"user":{"displayName":"Kane Huang","photoUrl":"","userId":"02321211776127070843"}},"colab":{"base_uri":"https://localhost:8080/","height":106}},"source":["# tf.saved_model.save(subject_model, \"drive/ML_Study/saved_model/subject_model_200330v2\")\n","# subject_model = tf.saved_model.load(\"drive/ML_Study/saved_model/subject_model_200330\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","INFO:tensorflow:Assets written to: drive/ML_Study/saved_model/subject_model_200330/assets\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B1LAHv_LWJeJ","colab_type":"code","colab":{}},"source":["def extract_Ss(text):\n","    maxlen=128\n","    tokens = tokenizer.tokenize(text, max_length=maxlen)\n","    a,b,c= tokenizer.encode_plus(text,max_length=maxlen,pad_to_max_length=True).values()\n","\n","    _a = tf.convert_to_tensor(tf.constant([a])) # 输入model用\n","    _b = tf.convert_to_tensor(tf.constant([b]))\n","    _c = tf.convert_to_tensor(tf.constant([c]))\n","    token_id = np.array(a) # decode用\n","    # 抽取subject\n","    input_text={'input_ids':_a, 'attention_mask':_b, 'token_type_ids':_c}\n","    subject_preds = subject_model.predict(input_text)\n","    subject_preds = tf.nn.softmax(subject_preds)\n","    print(subject_preds)\n","    # 输出坐标\n","    start = np.where(subject_preds[0, :, 0] > 0.5)[0] \n","    end = np.where(subject_preds[0, :, 1] > 0.5)[0]\n","    subjects = []\n","    \n","    for i in start:\n","        j = end[end >= i]\n","        if len(j) > 0:\n","            j = j[0]\n","            subjects.append((i, j))\n","    # subjects=[(1,3)]\n","    if subjects:\n","        rt = []\n","        for s in subjects:\n","            sub = tokenizer.decode(token_id[s[0]:s[1] + 1])\n","            rt.append(sub)\n","        return rt\n","    else:\n","        return []"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PEJt3_tLozNO","colab_type":"code","outputId":"6be5f178-f5f1-4d8e-9208-0ad9a3661677","executionInfo":{"status":"ok","timestamp":1585578542671,"user_tz":-480,"elapsed":1056,"user":{"displayName":"Kane Huang","photoUrl":"","userId":"02321211776127070843"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["text1 = '抗美援朝胜利后，张仲先将军回国与杨郁芬女士喜结连理' # 张仲先\n","text = \"2013年4月21日，由潇湘电影集团有限公司与四川省阿坝州金川县政府联合出品的电影《马奈的新娘》在北京首映，影片反映嘉绒藏族民俗文化和藏区自然风光，以东女国文化为核心，展示了国家非物质文化遗产——宫廷歌舞马奈锅庄\"\n","text = '亚伦的配音则是下野纮（又是悠哥）'\n","\n","rt = extract_Ss(text)\n","rt = np.array(rt)\n","print(rt)\n","# tokens = tokenizer.tokenize(text, max_length=256)\n","# _tokens = np.array(tokens)\n","# a,b,c= tokenizer.encode_plus(text=s1,max_length=256,pad_to_max_length=True).values()\n","# _a = np.array(a)\n","# sub = tokenizer.decode(_a[s[0]:s[1] + 1])\n","# print(sub)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tf.Tensor(\n","[[[0.4999351  0.5000649 ]\n","  [0.51770717 0.48229286]\n","  [0.49367487 0.5063251 ]\n","  [0.50605714 0.49394283]\n","  [0.5088337  0.4911663 ]\n","  [0.512335   0.487665  ]\n","  [0.50033456 0.4996654 ]\n","  [0.503017   0.496983  ]\n","  [0.509054   0.49094602]\n","  [0.5070284  0.4929716 ]\n","  [0.5025168  0.49748313]\n","  [0.49627772 0.50372225]\n","  [0.49555278 0.5044472 ]\n","  [0.5062518  0.4937482 ]\n","  [0.49301806 0.50698197]\n","  [0.50545007 0.4945499 ]\n","  [0.49871972 0.50128025]\n","  [0.5004256  0.4995744 ]\n","  [0.49063855 0.50936145]\n","  [0.4979298  0.5020702 ]\n","  [0.4953353  0.50466466]\n","  [0.50044465 0.49955535]\n","  [0.50229204 0.49770796]\n","  [0.49797124 0.50202876]\n","  [0.4944411  0.50555885]\n","  [0.49557048 0.5044295 ]\n","  [0.49960262 0.5003974 ]\n","  [0.4992849  0.50071514]\n","  [0.49917552 0.50082445]\n","  [0.49445322 0.5055468 ]\n","  [0.5006062  0.4993938 ]\n","  [0.50126886 0.49873114]\n","  [0.500177   0.49982294]\n","  [0.502066   0.49793398]\n","  [0.5019876  0.4980124 ]\n","  [0.50014985 0.49985018]\n","  [0.49802637 0.5019736 ]\n","  [0.49821433 0.5017857 ]\n","  [0.5004674  0.49953252]\n","  [0.49826485 0.5017352 ]\n","  [0.50035363 0.4996464 ]\n","  [0.50023156 0.4997684 ]\n","  [0.50005966 0.49994037]\n","  [0.50006825 0.49993178]\n","  [0.49931428 0.5006857 ]\n","  [0.4997927  0.5002073 ]\n","  [0.49999055 0.5000095 ]\n","  [0.49964556 0.5003544 ]\n","  [0.49840704 0.501593  ]\n","  [0.4997699  0.5002301 ]\n","  [0.49990678 0.5000932 ]\n","  [0.5005274  0.4994726 ]\n","  [0.50001025 0.49998978]\n","  [0.50078666 0.49921334]\n","  [0.50033617 0.4996638 ]\n","  [0.49956334 0.50043666]\n","  [0.49956068 0.5004393 ]\n","  [0.50005734 0.4999427 ]\n","  [0.50031185 0.49968815]\n","  [0.50088036 0.4991196 ]\n","  [0.4993649  0.50063515]\n","  [0.5000563  0.4999437 ]\n","  [0.5002996  0.49970046]\n","  [0.49965227 0.50034773]\n","  [0.4996557  0.5003443 ]\n","  [0.5000195  0.4999805 ]\n","  [0.49939188 0.5006081 ]\n","  [0.4994868  0.5005132 ]\n","  [0.5002689  0.49973112]\n","  [0.50030917 0.49969086]\n","  [0.50000405 0.49999598]\n","  [0.49996302 0.500037  ]\n","  [0.49984887 0.5001511 ]\n","  [0.49993303 0.500067  ]\n","  [0.49913278 0.50086725]\n","  [0.49975917 0.5002408 ]\n","  [0.49975303 0.500247  ]\n","  [0.5000012  0.49999878]\n","  [0.49982435 0.50017565]\n","  [0.50010073 0.49989927]\n","  [0.4997909  0.5002091 ]\n","  [0.49972916 0.5002708 ]\n","  [0.4997423  0.50025773]\n","  [0.5001383  0.49986172]\n","  [0.49988002 0.5001199 ]\n","  [0.49998826 0.50001174]\n","  [0.4999424  0.5000576 ]\n","  [0.4994105  0.5005895 ]\n","  [0.49934733 0.5006527 ]\n","  [0.49983105 0.5001689 ]\n","  [0.4997822  0.5002178 ]\n","  [0.49962777 0.50037223]\n","  [0.49972463 0.5002754 ]\n","  [0.4998684  0.5001316 ]\n","  [0.50002056 0.4999794 ]\n","  [0.5001209  0.49987906]\n","  [0.4998893  0.5001107 ]\n","  [0.5002477  0.49975228]\n","  [0.5001502  0.49984983]\n","  [0.5001188  0.4998812 ]\n","  [0.50001323 0.49998677]\n","  [0.4999987  0.5000013 ]\n","  [0.4997584  0.50024164]\n","  [0.49992415 0.5000759 ]\n","  [0.49959517 0.5004048 ]\n","  [0.49995035 0.50004965]\n","  [0.49975643 0.5002436 ]\n","  [0.50033426 0.49966577]\n","  [0.49979886 0.5002011 ]\n","  [0.50004786 0.49995217]\n","  [0.4996867  0.5003133 ]\n","  [0.49970886 0.5002911 ]\n","  [0.5000841  0.49991593]\n","  [0.5000185  0.49998152]\n","  [0.4998174  0.5001826 ]\n","  [0.49999034 0.50000966]\n","  [0.4999303  0.5000697 ]\n","  [0.5001316  0.4998684 ]\n","  [0.5000505  0.49994949]\n","  [0.5000186  0.4999814 ]\n","  [0.5000712  0.49992877]\n","  [0.5001534  0.49984658]\n","  [0.50002295 0.49997702]\n","  [0.49999884 0.50000113]\n","  [0.4999545  0.50004554]\n","  [0.49999222 0.5000078 ]\n","  [0.500001   0.49999896]\n","  [0.5000223  0.49997774]]], shape=(1, 128, 2), dtype=float32)\n","['亚 伦' '的 配 音 则 是 下 野 [UNK] （' '配 音 则 是 下 野 [UNK] （' '音 则 是 下 野 [UNK] （'\n"," '则 是 下 野 [UNK] （' '是 下 野 [UNK] （' '下 野 [UNK] （' '野 [UNK] （' '[UNK] （'\n"," '是 悠' '哥 ）' '[SEP] [PAD]' '[PAD] [PAD] [PAD]' '[PAD] [PAD]'\n"," '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'\n"," '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD]' '[PAD] [PAD] [PAD] [PAD] [PAD]'\n"," '[PAD] [PAD] [PAD] [PAD]' '[PAD] [PAD] [PAD]' '[PAD] [PAD]' '[PAD] [PAD]'\n"," '[PAD] [PAD] [PAD] [PAD] [PAD]' '[PAD] [PAD] [PAD] [PAD]'\n"," '[PAD] [PAD] [PAD]' '[PAD] [PAD]' '[PAD] [PAD] [PAD] [PAD] [PAD]'\n"," '[PAD] [PAD] [PAD] [PAD]' '[PAD] [PAD] [PAD]' '[PAD] [PAD]'\n"," '[PAD] [PAD] [PAD] [PAD]' '[PAD] [PAD] [PAD]' '[PAD] [PAD]'\n"," '[PAD] [PAD] [PAD]' '[PAD] [PAD]' '[PAD] [PAD]' '[PAD] [PAD] [PAD] [PAD]'\n"," '[PAD] [PAD] [PAD]' '[PAD] [PAD]' '[PAD] [PAD]' '[PAD] [PAD]'\n"," '[PAD] [PAD]' '[PAD] [PAD] [PAD]' '[PAD] [PAD]'\n"," '[PAD] [PAD] [PAD] [PAD] [PAD]' '[PAD] [PAD] [PAD] [PAD]'\n"," '[PAD] [PAD] [PAD]' '[PAD] [PAD]' '[PAD] [PAD]' '[PAD] [PAD]'\n"," '[PAD] [PAD] [PAD]' '[PAD] [PAD]'\n"," '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'\n"," '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD]' '[PAD] [PAD] [PAD] [PAD] [PAD]'\n"," '[PAD] [PAD] [PAD] [PAD]' '[PAD] [PAD] [PAD]' '[PAD] [PAD]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nUmaRPpaJSRH","colab_type":"code","outputId":"5b84a4ab-f080-4747-b240-a0da4d5148b6","executionInfo":{"status":"ok","timestamp":1585574357813,"user_tz":-480,"elapsed":761,"user":{"displayName":"Kane Huang","photoUrl":"","userId":"02321211776127070843"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["a = np.zeros((4,7,2))\n","a[0,2,0] = 1\n","a[0,4,1] = 1\n","a[0,5,0] = 1\n","a[0,6,1] = 1\n","b = np.zeros((4,7,2))\n","start = np.where(a[0, :, 0] > 0.6)[0]\n","end = np.where(a[0, :, 1] > 0.5)[0]\n","# tf.reduce_sum(tf.keras.losses.binary_crossentropy(a, b),axis=1)\n","rt = np.array(myloss(a,b))\n","rt1 = np.array(tf.keras.losses.binary_crossentropy(a[0],a[1]))\n","print(rt)\n","print(rt1.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[30.84989694 -0.         -0.         -0.        ]\n","(7,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NlPe5q1SJ09N","colab_type":"code","outputId":"4fc52559-c361-4107-ad4b-31ed26920e96","executionInfo":{"status":"ok","timestamp":1585572410639,"user_tz":-480,"elapsed":573,"user":{"displayName":"Kane Huang","photoUrl":"","userId":"02321211776127070843"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["m = tf.keras.metrics.BinaryAccuracy()\n","r = m.update_state(a, b)\n","print(m.result().numpy())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0.9285714\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WfZh3u2DeoIl","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}